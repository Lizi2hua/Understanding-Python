# 【MTCNN】Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks(使用多任务级联卷积网络进行联合人脸检测和对齐[^1])

## 1.摘要 

​		由于各种姿势，光照度和遮挡物，在无约束的环境中人脸检测和对齐具有挑战性。最近的研究表明，深度学习方法可以在这两个任务上取得令人印象深刻的性能。在本文中，我们提出了一个**深度级联多任务框架**，它利用了检测和对齐之间的内在关联性以提高其性能。特别是，我们的框架充分利用级联架构，通过三个阶段的仔细设计的深度卷积网络，以**粗到细**的方式预测人脸和地标位置。我们的方法在具有挑战性的人脸检测FDDB和WIDER FACE基准，以及人脸对齐AFLW基准上，在保持实时性能的前提下，实现了优于最先进技术的准确性。



## 2.  Introduction

​		Yang等人训练深度卷积神经网络用于人脸属性识别，获得**人脸区域的高相应**，进一步来**（根据高相应区域）产生人脸候选窗**。但由于其复杂的网络结构，实际中是time costly。

​		人脸对齐方面的研究大致分为两类：1.基于回归的方法；2.基于模板匹配（template fitting）的方法。

​		但是，大多数先前的人脸检测和人脸对齐方法忽略了两者的内在联系。

​		Zhang等人使用多任务CNN来提高多角度（multi view)人脸识别的准确率，但是检测任务的recall受限于初始的弱检测器的检测窗口（detection window）。

​		另一方面，**难例挖掘对加强检测器的能力是至关重要的。**传统的难例挖掘通常是以离线的方式进行的，这大大增加了人工的操作。需要设计一种**在线的难例挖掘**方法，它能自适应当前的训练状态。

​		本文中，提出了一新的框架来整合这2个任务，该框架使用了统一的、级联的CNNs，通过多任务学习来完成2个任务。提出的CNNs由3个阶段组成：

``stage1:使用一个浅(shallow)的CNN来快速生成大量的候选窗；
stage2:使用一个更复杂的CNN来拒绝大量的含有非人脸的窗；
stage3:使用一个更强大的CNN再次细化结果，并输出5个面部landmark位置。``

![image-20200729110234874](src/MTCNN)

Fig.1. 级联架构的Pipeline。包括3个阶段，生成候选窗口的、速度快的建议网络（Proposal Network)P-Net,细化候选窗的细化网络（Refinement Network)R-Net,第三步，输出网络O-Net。

文章的贡献：

1.提出了一种新的级联CNNs的人脸检测与对齐框架，并精心设计了轻量的CNN架构以提高实时性能；

2.提出了一种有效的在线难例挖掘方法来提高性能；

3.在具有挑战的landmark上进行了广泛的实验，同时也和人脸检测和人脸对齐任务的state-of-art技术做了对比，显示了卓越的性能和表现。

### 2.1 Approach

**A: Overall**

​	**Stage1**:利用一个全卷积网络称为P-Net以获得候选面部窗口和bounding box 回归向量。然后根据估计的bbox回归向量对候选窗口进行校准。之后通过非极大值抑制 (NMS)来合并高度重叠的候选窗。

​	**Stage2**:所有的候选窗都被输入另外一个CNN，R-Net。R-Net会拒绝掉大量的伪候选窗，用边界框回归（任务）进行校准，并进行NMS。

​	**Stage3**:这一阶段与第二阶段类似，但这一阶段中，我们的目标是用更多的监督（指图片大小还是训练方式？）来识别面部区域。特别地，该网络将会输出5个面部landmark位置。

**B: CNN架构**

卷积神经网络的性能可能被如下的事实限制：

1.卷积层的卷积核缺乏多样性可能会限制其辨别能力。（指卷积层的深度还是个数？）

2.与其他儿得多类别目标检测和分类任务相比，面别检测是一个具有挑战性的**二分类任务**。为此，我们减少了卷积核的个数，并将$5\times5$的卷积核变为$3\times3$的卷积核。这样，可以减少计算量和提高深度，从而提高网络的性能。（2层$3\times3$的卷积核的感受野等效于一层$5\times5$卷积核的卷积层，当时深度增加了。）

这些改进可以减少运行时间。

**使用PReLU作为卷积和全连接层后的激活函数。**

**C：Training**

使用3个任务来训练CNN检测器：判断是否为面部的二分类问题，bbox回归和面部landmark定位。

:one::面部的二分类问题。对于每个实例$x_i$，使用交叉熵损失。
$$
L_i^{det}=-(y_i^{det}log(p_i)+(1-y_i^{det})(1-log(p_i)))
$$
$p_i$是网络输出判断实例$x_i$是否为人脸的概率值，标记$y_i^{det}\in\{0,1\}$是标签的真值（ground-truth label)。

:two:bbox回归。对于每个候选窗，使用候选窗和真值之间的偏移量（边框的left,top,height,width之间偏移量）。学习目标被表述为一个回归问题，对每个实例使用欧式损失。
$$
L_i^{box}=||\hat{y}_i^{box}-y_i^{box}||^2
$$
:three:面部landmark定位。和bbox回归任务相似，面部landmark定位也最小化欧式距离。
$$
L_i^{landmark}=||\hat{y}^{landmark}-y_i^{landmark}||_2^2
$$
有5个面部landmark，左右眼，鼻子，左右嘴角。所以$y_i^{landmark}\in R^{10}$。

:four:多源训练。因为我们对每个网络使用不同任务，所以在**训练图片中有不同类型的图片**。这种情况下，一些损失函数并不总是被使用。比如，**背景区域的实例，只需计算$L_i^{det}$，其他两个损失函数被设置为0。**这种情况可以使用一个实例类型（sample type)指示器来实现。学习目标可以变为：
$$
min\sum_{i=1}^{N}\sum j\in\{det,box,landmark\}\alpha_j\beta_i^jL_i^j
$$
$N$是训练实例的个数，$\alpha_j$代表着任务的重要程度，在P-Net和R-Net使用$(\alpha_{det}=1,\alpha_{box}=0.5,\alpha_{landmark}=0.5)$

在O-Net中使用$(\alpha_{det}=1,\alpha_{box}=0.5,\alpha_{landmark}=1)$获得更精确的landmark定位。

$\beta_i^j \in\{0,1\}$实例类型指示器。

:five:在线难例挖掘。**具体的在每个mini-batch中，对每个实例（样本）在前向过程中计算的损失排序，将top 70%作为难例，接着只计算这些难例在反向传播的梯度。**这意味着，在训练过程中忽略了简单样本（易学习的样本），这些简单样本对增强检测器的能力鲜有帮助。实验表明该策略有更好的性能。

## 3.EXPERIMENTS

**A: Training Data**

​	在训练工程中使用4中不同的数据标注。

1. 负例。对于任何面部真值（ground-truth faces）的IoU小于0.3
2. 正例。与真值的IoU大于0.65
3. 脸的部分（类似于只有鼻子这种？）。IoU在0.4和0.65之间。
4. 脸部landmarks。标记了5个landmark的位置的标签

在*脸的部分*和负例之间没有清晰的界限，而且不同的脸部标注存在差异。**正负例用于脸部分类任务，正例和脸的部分用于bbox回归，landmark用于脸部landmark定位任务。**

总的训练数据按照3：1：1：2组成。

每个网络使用的数据集如下：

1. P-Net。从**WIDER FACE**数据集随机裁剪几块来收集正例、负例和脸的部分。从**CelebA**裁剪脸来用作landmark。
2. R-Net[^2]。使用第一阶段在WIDER FACE数据集上进行检测，并收集正例，负例，部分人脸，面部landmark从CelebA检测得到。（即R-Net的训练数据由P-Net生成）（We use the first stage of framework to detect faces from WIDER FACE to collect positives,negetives and part face while landmark faces are detected form CelebA）（*这样做可以将P-Net和R-Net在上下文上联系起来？*）
3. O-Net。类似于R-Net,但我们使用前两阶段来检测面部和收集数据（来训练）。



[^1]: 脸对齐的目的是定位出人脸面部关键点的位置，这些关键点通常是人脸中具有语义的器官，比如人的眼睛、眉毛、鼻子、嘴巴等位置。
[^2]:R-Nert的训练：https://zhuanlan.zhihu.com/p/32121614





